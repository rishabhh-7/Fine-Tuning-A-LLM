{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCDvShOkGOpL"
      },
      "source": [
        "# Download Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vySJ9lRxGOpN"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers datasets peft bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufXpOqoPGOpO"
      },
      "source": [
        "# Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1nbzKh0kRMn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from datasets import load_dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12RfrbHkGOpP"
      },
      "source": [
        "# Load Pretrained model and configure 4 bit Quantisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v1wFwozkU_B"
      },
      "outputs": [],
      "source": [
        "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
        "\n",
        "# Configure 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False\n",
        ")\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-zwPy4lGOpP"
      },
      "source": [
        "# Apply LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ0-imDvkqZE",
        "outputId": "f6e124fe-7a53-4a0c-e47e-6d98376243d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,572,864 || all params: 1,317,148,672 || trainable%: 0.1194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMC5LbXGOpQ"
      },
      "source": [
        "# Load Wikitext Dataset and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "77c05d8479ab4967867fa40235a33945",
            "755781eb3e7a456d820b19fd4553306b",
            "3d561a28b8ed4a44a2c2444b80af3f2e",
            "9d4c940ce8334b4a8f1f297c845b3bfa",
            "5833a87c9cbd4b85a61059c62be9e907",
            "1d84900d497b444e8615a934f2bbe740",
            "29c57aa0f33b49edae103054561a309b",
            "4f6629bfb5d9482bbbd6ab41ee5c1ec8",
            "05ba0b345bda4f92852b29488b8504c7",
            "2830ef04c76946dc8ced3cbc819a0657",
            "3ebb8e07be7248cfa6b7492b5822d5c4",
            "0ca966dc5f9f4d468d157287d9015267",
            "7dbc8ce813e64aaeb2683f7eabbd8327",
            "0904f3009ddd44c1bb306a00f8d3a689",
            "e80647331a404f11970cac09d1c46aa1",
            "be252ab5b5fe4b01aeb8a8d757789f5a",
            "7de2d6c5ab8e4fde8c9896292ca4cba7",
            "65cba742b7c641bf99e90d61a310db35",
            "2ac164b76e614cfcbe8b9ffb7449e007",
            "f72d1cd5ce314c53bb1502248b03391e",
            "1b7fd53250d442e59ad0fd4bc9958339",
            "63b8fbbeb8394505a0e44e384686ab1f",
            "a0f8ccbfc8454cd3b315ce6b8450b711",
            "1084d5f34e594fda9407e5d6e8d21766"
          ]
        },
        "id": "HRQqaADplMy8",
        "outputId": "4e9fcb4f-1244-4f2d-d973-41a4a03e02bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0f8ccbfc8454cd3b315ce6b8450b711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1084d5f34e594fda9407e5d6e8d21766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split={'train': 'train[:5000]', 'validation': 'validation[:1000]'})\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Apply tokenization while preserving splits\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Now we can access the splits correctly\n",
        "train_dataset = tokenized_dataset[\"train\"]\n",
        "eval_dataset = tokenized_dataset[\"validation\"]\n",
        "\n",
        "def add_labels(examples):\n",
        "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
        "    return examples\n",
        "\n",
        "train_dataset = train_dataset.map(add_labels, batched=True)\n",
        "eval_dataset = eval_dataset.map(add_labels, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbRYGUD-GOpQ"
      },
      "source": [
        "# Provide the Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqDizGCjmIjS",
        "outputId": "3fbb5619-7b5c-413d-88ef-90eb5c1f0920"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1584/382730666.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    eval_steps=100,\n",
        "    save_steps=100,\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKeqYZKzGOpR"
      },
      "source": [
        "# Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "ryh-BAFomMHS",
        "outputId": "b59b72ce-24cf-44e0-bb36-3d09ac3fcd54",
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 08:07, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.461400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.558300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.662100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.590200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.261800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.441500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.769300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.174500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.294000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>3.828800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.625400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.494300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.990400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.144600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>3.150300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>3.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.495000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.591500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.705000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>3.399600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.223100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.358200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>3.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>3.331200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>3.391800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>3.321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.398000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>3.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>3.547900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>3.398500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>3.348300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>3.487800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>3.290300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>3.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>3.723400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.360800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>3.478100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>3.500900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>3.270300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>3.442300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.373500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>3.467000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>3.317500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>3.331800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>3.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>3.355700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>3.188700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>3.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.173800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>3.329600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>3.708700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>3.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>3.419900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.476200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>3.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>3.510900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>3.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>3.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.634400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>3.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>3.523700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>3.375400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>3.357100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.310700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>3.090900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>3.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>3.546700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>3.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.310900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>3.816700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>3.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>3.205400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>3.290600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.284000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>3.258700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>3.354700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>3.287400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>3.130800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.367200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>3.426200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>3.249500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>3.225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>3.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>3.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>3.267900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>3.385000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>3.569300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.175400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>3.734900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>3.461900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>3.135400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>3.079500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.237600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>3.517900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>3.178600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>3.582600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>3.228600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.327800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>3.718100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>3.430300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>3.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>3.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.977500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>3.315500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>3.415400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>3.240900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>3.206100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.309100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>3.147200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>3.787600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>2.974900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>3.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.472800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>3.443000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>3.497700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>3.338200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>3.297800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>3.162800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>3.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>3.695400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>3.361600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>3.506400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>3.222800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>3.376500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>3.327800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>3.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>3.445200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>3.339000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>3.155400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>3.268400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>3.285400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>3.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>3.301800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>3.515500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>3.485100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>3.785800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>3.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>3.150300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>3.819700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>3.440800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>3.470400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.127000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>3.704300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>3.264800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>3.198000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>3.485300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>3.244700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>3.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>3.310700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>3.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>3.502500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>3.317100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>3.234100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>3.214400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>3.191900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>3.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>3.306100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>3.259300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>3.524100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>3.168700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>3.572700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>3.477300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>3.533400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>3.510600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>3.645700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>3.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>3.306000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>3.485100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>3.096100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>2.986600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>3.553100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.222700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>3.518900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>3.200200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>3.814600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>3.136700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>3.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>3.597400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>3.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>3.478300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>3.206100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>3.210400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>3.582000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>3.238900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>3.519300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>3.235200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>3.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>3.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>3.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>3.476800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>3.360800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.624600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>3.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>3.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>3.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>3.643500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>3.589500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>3.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>3.463800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>3.384300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>3.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>3.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>3.342900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>3.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>3.601100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>3.215400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>3.214200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>3.173300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>3.295900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>3.205500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>3.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>3.350900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>3.215000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>3.500100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>3.552300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>3.875400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>3.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>3.527600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>3.278400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>3.559100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>3.510500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>3.414200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>3.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>3.207800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>3.185700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>3.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>3.643700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>3.231600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>3.338200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>3.173200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>3.571100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>3.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>3.356900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>3.465700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>3.312900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>3.534700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>3.767200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>4.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>3.194400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>3.342800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>2.992500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.384100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(\"fine-tuned-lora-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Y5DjCrGOpR"
      },
      "source": [
        "# Quantitative Analysis of Base Model and Fine Tuned Model by comparing Perplexities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "ZNywiJyunMxt",
        "outputId": "034dded9-573a-49a6-eea0-51e9648796c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating perplexities...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging PEFT adapters...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Results:\n",
            "Base Model Perplexity: 45.79\n",
            "Fine-Tuned Model Perplexity: 20.21\n"
          ]
        }
      ],
      "source": [
        "def calculate_perplexity(model, dataset, max_samples=50):\n",
        "\n",
        "    eval_dataset = dataset.select(range(min(len(dataset), max_samples)))\n",
        "\n",
        "    # For PEFT models, we need to merge and unload first\n",
        "    if hasattr(model, \"peft_config\"):\n",
        "        model = model.merge_and_unload()\n",
        "        torch.cuda.empty_cache()\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "        pad_to_multiple_of=8\n",
        "    )\n",
        "\n",
        "    eval_args = TrainingArguments(\n",
        "        output_dir=\"./eval_temp\",\n",
        "        per_device_eval_batch_size=2,\n",
        "        fp16=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=eval_args,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    eval_results = trainer.evaluate(eval_dataset)\n",
        "    loss = eval_results[\"eval_loss\"]\n",
        "\n",
        "    if torch.isnan(torch.tensor(loss)).any():\n",
        "        raise ValueError(\"NaN loss detected\")\n",
        "\n",
        "    perplexity = torch.exp(torch.tensor(loss)).item()\n",
        "    return perplexity\n",
        "\n",
        "base_model_eval = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Load fine-tuned model with adapters\n",
        "peft_model = PeftModel.from_pretrained(\n",
        "    AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16),\n",
        "    \"fine-tuned-lora-model\"\n",
        ")\n",
        "\n",
        "# Calculate perplexities\n",
        "base_ppl = calculate_perplexity(base_model_eval, tokenized_dataset[\"validation\"])\n",
        "peft_ppl = calculate_perplexity(peft_model, tokenized_dataset[\"validation\"])\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"Base Model Perplexity: {base_ppl:.2f}\")\n",
        "print(f\"Fine-Tuned Model Perplexity: {peft_ppl:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sybVeDGVGOpR"
      },
      "source": [
        "# Qualitative Analysis by generating 10 samples and assigning a score to base and fine tuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qagXH74tnPRC",
        "outputId": "95d761fd-9bf1-4f16-b0dc-b8489c446f3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 1:\n",
            "Base: Analyze the trade-offs between renewable and non-renewable energy sources in 100 words or less\n",
            "\n",
            "Renewable energy is one of the most attractive energy sources for the future. The renewable energy industry has grown by leaps and bounds since the 1990s. The market has grown from $120 billion in 2007 to $400 billion in 2013. The growth of the renewable energy market is attributed to the wide variety of renewable energy sources used in the energy sector and the high level of technological innovation\n",
            "Fine-Tuned: Analyze the trade-offs between renewable and non-renewable energy sources in 100 words or less\n",
            "\n",
            "We’re on a roll now, but the energy sector is not. I’m not even going to try to get into why. But the industry is trying to change its thinking. And the energy sector is trying to change its thinking. And we’re going to see more of the same in the coming weeks.\n",
            "\n",
            "As of mid-February 2018,\n",
            "\n",
            "Sample 2:\n",
            "Base: Given the rapid advancements in AI, discuss three ethical concerns that policymakers should prioritize in 100 words or less.\n",
            "\n",
            "In this essay, I’ll explore three issues that are often discussed in AI ethics and lay out my view of each.\n",
            "\n",
            "The ethics of AI should not be discussed in isolation from the broader question of AI ethics.\n",
            "\n",
            "The Ethics of AI\n",
            "\n",
            "We can’t stop AI. There is no way to tell AI where it should be and there are no\n",
            "Fine-Tuned: Given the rapid advancements in AI, discuss three ethical concerns that policymakers should prioritize in 100 words or less.\n",
            "\n",
            "In the past, AI, especially its first-generation generation, was considered a black box. AI is largely still black box. The AI is a black box. AI is black box. AI is black box.\n",
            "\n",
            "The black box of AI is the AI that is not fully autonomous, is not fully autonomous, is not fully autonomous, is not fully autonomous, is not fully\n",
            "\n",
            "Sample 3:\n",
            "Base: Explain the difference between gradient descent and stochastic gradient descent, including when to use each in 100 words, and when to use each in 100 words and 100 sentences.\n",
            "\n",
            "It is very common for people to use a neural network as the base model for a model that takes in a particular data set, and then does a particular transformation on the data, such as scaling it to a certain range, or reducing it to a certain range, and so on. In this situation, the neural\n",
            "Fine-Tuned: Explain the difference between gradient descent and stochastic gradient descent, including when to use each in 100 words or less.\n",
            "\n",
            "Hi, I'm new to machine learning, I just need a little help to understand the difference between gradient descent and stochastic gradient descent.\n",
            "I have this:\n",
            "x_i = [0,1,2,3,4]\n",
            "y_i = [1,2,3,4,5]\n",
            "\n",
            "I want to find the\n",
            "\n",
            "Sample 4:\n",
            "Base: Summarize the key events of the French Revolution and their impact on modern democracies in 150 words in 100 words per minute.\n",
            "\n",
            "The French Revolution was the most important event in the history of the modern world. It was the birth of the modern nation-state, the greatest transformation in human history. It was a period of profound upheaval and change in the global political and economic system. It was the beginning of the end of absolutist monarchy, and the beginning of the rise of liberal\n",
            "Fine-Tuned: Summarize the key events of the French Revolution and their impact on modern democracies in 150 words in 100 words or fewer.\n",
            "\n",
            "Key Ideas\n",
            "\n",
            "1789–1795: The Reign of Terror\n",
            "\n",
            "The French Revolution of 1789–1795 began when a group of people in the Paris suburb of Saint-Denis decided to take things into their own hands. They were not satisfied with the order and justice of the French government, and decided to take control of the country.\n",
            "\n",
            "\n",
            "Sample 5:\n",
            "Base: Compare the transformer architecture to previous RNN-based models in natural language processing in 100 words.\n",
            "\n",
            "1\n",
            "\n",
            "2\n",
            "\n",
            "3\n",
            "\n",
            "4\n",
            "\n",
            "5\n",
            "\n",
            "6\n",
            "\n",
            "7\n",
            "\n",
            "8\n",
            "\n",
            "9\n",
            "\n",
            "10\n",
            "\n",
            "11\n",
            "\n",
            "12\n",
            "\n",
            "13\n",
            "\n",
            "14\n",
            "\n",
            "15\n",
            "\n",
            "16\n",
            "\n",
            "17\n",
            "\n",
            "18\n",
            "\n",
            "19\n",
            "\n",
            "20\n",
            "\n",
            "21\n",
            "\n",
            "22\n",
            "\n",
            "23\n",
            "\n",
            "24\n",
            "\n",
            "25\n",
            "\n",
            "26\n",
            "\n",
            "27\n",
            "Fine-Tuned: Compare the transformer architecture to previous RNN-based models in natural language processing in 100 words or less.\n",
            "- We provide a detailed analysis of the baseline model and the two variants of our model in 100 words or less.\n",
            "- We provide a detailed analysis of the baseline model and the two variants of our model in 100 words or less.\n",
            "- We provide a detailed analysis of the baseline model and the two variants of our model in 100 words or less.\n",
            "- We provide a detailed analysis\n",
            "\n",
            "Sample 6:\n",
            "Base: Explain the theory of relativity in simple terms for someone with no scientific background in 100 words.\n",
            "\n",
            "I'm looking for a way to explain the theory of relativity, specifically the General Theory of Relativity, to someone with no science background, without having to explain every detail in 100 words.\n",
            "\n",
            "I'm aware of the basic form of the theory, and I understand the steps needed to understand it, but I was hoping to leave the theory as a simple explanation, and leave it at that\n",
            "Fine-Tuned: Explain the theory of relativity in simple terms for someone with no scientific background in 100 words.\n",
            "\n",
            "What is the difference between an inertial reference frame and an inertial system?\n",
            "\n",
            "The phrase “inertial system” is an extremely vague and abstract concept. Most people use the term to mean an inertial reference frame. A few people use the term to mean an inertial system. But to me, an inertial system is not an inertial reference frame. I\n",
            "\n",
            "Sample 7:\n",
            "Base: Describe the significance of the fall of the Berlin Wall in 1989 and its impact on global geopolitics in 100 words.\n",
            "\n",
            "The fall of the Berlin Wall in 1989 forever changed the course of global geopolitics and ushered in the era of global democracy. It set the stage for the new post-Cold War era, a period of great hope for humanity. A period of great optimism for a new world order in which the power of nation states would be challenged and dismantled by the rise of a new\n",
            "Fine-Tuned: Describe the significance of the fall of the Berlin Wall in 1989 and its impact on global geopolitics in 100 words.\n",
            "\n",
            "The fall of the Berlin Wall in 1989 marked the end of the Cold War—the Cold War over which the United States and the Soviet Union had fought in the late 1940s. The Wall, a 2.2-mile-tall concrete and brick tower, fell in the center of Berlin on November 9, 1989, as the Berlin Wall had for many years. It\n",
            "\n",
            "Sample 8:\n",
            "Base: Compare the economic systems of capitalism and socialism, including their strengths and weaknesses in 100 words. The following is a summary of the Economic Systems of Capitalism and Socialism.\n",
            "\n",
            "Capitalism is a system of capitalism. Capitalism, a system of capitalism, is a system of capitalism. It is a system of capitalism. Capitalism is a system of capitalism and it is a system of capitalism. Capitalism is a system of capitalism. Capitalism is a system of capitalism. Capitalism is a system of capitalism. Capitalism is a\n",
            "Fine-Tuned: Compare the economic systems of capitalism and socialism, including their strengths and weaknesses in 100 words.\n",
            "\n",
            "1. Socialism and capitalism are competing forms of social organization, and socialism is the most advanced, best organized, and best supported.\n",
            "\n",
            "2. Socialism is the highest and most efficient form of social organization.\n",
            "\n",
            "3. Capitalism is the lowest form of social organization, and is highly inefficient.\n",
            "\n",
            "4. The most advanced forms of capitalism and socialism are the same.\n",
            "\n",
            "5.\n",
            "\n",
            "Sample 9:\n",
            "Base: Summarize the main contributions of Marie Curie to science and her impact on modern medicine in 100 words.\n",
            "\n",
            "This short summary of Marie Curie’s work was written by the founder of the Marie Curie Cancer Research Center, Dr. James Egan, on behalf of the Marie Curie Foundation. The original article can be found at: https://www.medicine.ohio-state.edu/news/2018/marie_curie_cancer_research\n",
            "Fine-Tuned: Summarize the main contributions of Marie Curie to science and her impact on modern medicine in 100 words.\n",
            "\n",
            "Marie Curie, an eminent scientist and Nobel laureate, created a revolution in modern medicine. Through her pioneering research in radioimmunoassay, she developed the fundamental concept of immunoassay and the method of immunohistochemistry. The development of the techniques of immunohistochemistry is still one of the most important achievements of modern medicine.\n",
            "\n",
            "Marie Curie\n",
            "\n",
            "Sample 10:\n",
            "Base: Explain the process of photosynthesis and its importance to life on Earth in 100 words.\n",
            "\n",
            "Photosynthesis is the process by which green plants take in oxygen and carbohydrates through the photosensory chlorophyll which is attached to the outside of the cell.\n",
            "\n",
            "Chlorophyll is a green pigment produced by plants that is used to absorb light as it is broken down into oxygen and carbon dioxide.\n",
            "\n",
            "During photosynthesis, oxygen is reduced to water and carbon dioxide, which are then\n",
            "Fine-Tuned: Explain the process of photosynthesis and its importance to life on Earth in 100 words.\n",
            "\n",
            "1. Photo-Cyano-Reduction\n",
            "\n",
            "2. The Cyanide Cycle\n",
            "\n",
            "3. The Carbon Cycle\n",
            "\n",
            "4. The Water Cycle\n",
            "\n",
            "5. The Food Cycle\n",
            "\n",
            "6. The Ozone Cycle\n",
            "\n",
            "7. The Nitrogen Cycle\n",
            "\n",
            "8. The Phosphorus Cycle\n",
            "\n",
            "9. The Phosphorus Cycle\n",
            "\n",
            "10. The Phosph\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompts = [\n",
        "    \"Analyze the trade-offs between renewable and non-renewable energy sources in 100 words\",\n",
        "    \"Given the rapid advancements in AI, discuss three ethical concerns that policymakers should prioritize in 100 words\",\n",
        "    \"Explain the difference between gradient descent and stochastic gradient descent, including when to use each in 100 words\",\n",
        "    \"Summarize the key events of the French Revolution and their impact on modern democracies in 150 words in 100 words\",\n",
        "    \"Compare the transformer architecture to previous RNN-based models in natural language processing in 100 words\",\n",
        "    \"Explain the theory of relativity in simple terms for someone with no scientific background in 100 words.\",\n",
        "    \"Describe the significance of the fall of the Berlin Wall in 1989 and its impact on global geopolitics in 100 words.\",\n",
        "    \"Compare the economic systems of capitalism and socialism, including their strengths and weaknesses in 100 words.\",\n",
        "    \"Summarize the main contributions of Marie Curie to science and her impact on modern medicine in 100 words.\",\n",
        "    \"Explain the process of photosynthesis and its importance to life on Earth in 100 words.\"\n",
        "]\n",
        "\n",
        "# Base model generation\n",
        "base_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=base_model_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Fine-tuned model generation\n",
        "finetuned_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Generate samples\n",
        "base_outputs = [base_pipeline(prompt)[0]['generated_text'] for prompt in prompts]\n",
        "finetuned_outputs = [finetuned_pipeline(prompt)[0]['generated_text'] for prompt in prompts]\n",
        "\n",
        "# Display outputs for manual evaluation\n",
        "for i, (base, finetuned) in enumerate(zip(base_outputs, finetuned_outputs)):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"Base: {base}\")\n",
        "    print(f\"Fine-Tuned: {finetuned}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WjF256qGOpS"
      },
      "source": [
        "# Human Analysis of the Outputs\n",
        "\n",
        "Sample 1:\n",
        "\n",
        "Base Model: 2/5 - Off-topic and lacks analysis.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Still off-topic, but more coherent than the base.\n",
        "\n",
        "Sample 2:\n",
        "\n",
        "Base Model: 2/5 - Incomplete and unfocused on key ethical concerns.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Repetitive, but attempts to highlight AI's challenges.\n",
        "\n",
        "Sample 3:\n",
        "\n",
        "Base Model: 1/5 - Off-topic and unclear.\n",
        "\n",
        "Fine-Tuned Model: 3/5 - Introduces relevant concepts, though still incomplete.\n",
        "\n",
        "Sample 4:\n",
        "\n",
        "Base Model: 2/5 - Vague and lacks detailed impact on democracies.\n",
        "\n",
        "Fine-Tuned Model: 3/5 - Offers more direct events, but still lacks full explanation of impact.\n",
        "\n",
        "Sample 5:\n",
        "\n",
        "Base Model: 2/5 - Not a clear comparison, lacks depth.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Repetitive, but some mention of the transformer’s models.\n",
        "\n",
        "Sample 6:\n",
        "\n",
        "Base Model: 1/5 - Unclear, not simplified.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Too technical, but attempts to clarify with examples.\n",
        "\n",
        "Sample 7:\n",
        "\n",
        "Base Model: 3/5 - Adequate but lacks deeper context.\n",
        "\n",
        "Fine-Tuned Model: 3/5 - Clearer but still lacks geopolitical context.\n",
        "\n",
        "Sample 8:\n",
        "\n",
        "Base Model: 1/5 - Repetitive and nonsensical.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Vague, but gives a basic attempt at comparison.\n",
        "\n",
        "Sample 9:\n",
        "\n",
        "Base Model: 1/5 - Incomplete and irrelevant.\n",
        "\n",
        "Fine-Tuned Model: 3/5 - Mentions contributions but lacks detail.\n",
        "\n",
        "Sample 10:\n",
        "\n",
        "Base Model: 2/5 - Vague, lacks clear process explanation.\n",
        "\n",
        "Fine-Tuned Model: 2/5 - Disjointed but covers cycles in the process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05ba0b345bda4f92852b29488b8504c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0904f3009ddd44c1bb306a00f8d3a689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac164b76e614cfcbe8b9ffb7449e007",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f72d1cd5ce314c53bb1502248b03391e",
            "value": 1000
          }
        },
        "0ca966dc5f9f4d468d157287d9015267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dbc8ce813e64aaeb2683f7eabbd8327",
              "IPY_MODEL_0904f3009ddd44c1bb306a00f8d3a689",
              "IPY_MODEL_e80647331a404f11970cac09d1c46aa1"
            ],
            "layout": "IPY_MODEL_be252ab5b5fe4b01aeb8a8d757789f5a"
          }
        },
        "1b7fd53250d442e59ad0fd4bc9958339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d84900d497b444e8615a934f2bbe740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2830ef04c76946dc8ced3cbc819a0657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c57aa0f33b49edae103054561a309b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac164b76e614cfcbe8b9ffb7449e007": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d561a28b8ed4a44a2c2444b80af3f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f6629bfb5d9482bbbd6ab41ee5c1ec8",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ba0b345bda4f92852b29488b8504c7",
            "value": 1000
          }
        },
        "3ebb8e07be7248cfa6b7492b5822d5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f6629bfb5d9482bbbd6ab41ee5c1ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5833a87c9cbd4b85a61059c62be9e907": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b8fbbeb8394505a0e44e384686ab1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65cba742b7c641bf99e90d61a310db35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755781eb3e7a456d820b19fd4553306b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d84900d497b444e8615a934f2bbe740",
            "placeholder": "​",
            "style": "IPY_MODEL_29c57aa0f33b49edae103054561a309b",
            "value": "Map: 100%"
          }
        },
        "77c05d8479ab4967867fa40235a33945": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_755781eb3e7a456d820b19fd4553306b",
              "IPY_MODEL_3d561a28b8ed4a44a2c2444b80af3f2e",
              "IPY_MODEL_9d4c940ce8334b4a8f1f297c845b3bfa"
            ],
            "layout": "IPY_MODEL_5833a87c9cbd4b85a61059c62be9e907"
          }
        },
        "7dbc8ce813e64aaeb2683f7eabbd8327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de2d6c5ab8e4fde8c9896292ca4cba7",
            "placeholder": "​",
            "style": "IPY_MODEL_65cba742b7c641bf99e90d61a310db35",
            "value": "Map: 100%"
          }
        },
        "7de2d6c5ab8e4fde8c9896292ca4cba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4c940ce8334b4a8f1f297c845b3bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2830ef04c76946dc8ced3cbc819a0657",
            "placeholder": "​",
            "style": "IPY_MODEL_3ebb8e07be7248cfa6b7492b5822d5c4",
            "value": " 1000/1000 [00:00&lt;00:00, 2417.90 examples/s]"
          }
        },
        "be252ab5b5fe4b01aeb8a8d757789f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80647331a404f11970cac09d1c46aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b7fd53250d442e59ad0fd4bc9958339",
            "placeholder": "​",
            "style": "IPY_MODEL_63b8fbbeb8394505a0e44e384686ab1f",
            "value": " 1000/1000 [00:00&lt;00:00, 5480.76 examples/s]"
          }
        },
        "f72d1cd5ce314c53bb1502248b03391e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
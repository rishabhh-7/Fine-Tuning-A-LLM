Base Model Used: EleutherAI GPT-1.3B

Dataset Used for Fine Tuning: Wikitext Dataset (a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia)

Methods Used: LoRA (Low Rank Approximation) and 4 - bit Quantisation

Colab Link to the project: https://colab.research.google.com/drive/1M3F-Kd5sb0rKbJEPxhETUgg6Zm2znZbG?usp=sharing
